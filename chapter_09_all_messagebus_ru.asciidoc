[[chapter_09_all_messagebus]]
== Едем в город на автобусе сообщений

((("events and the message bus", "transforming our app into message processor", id="ix_evntMBMP")))
((("message bus", "before, message buse as optional add-on")))
В этой главе мы начнем делать события более фундаментальными для внутренней структуры нашего приложения. Мы перейдем из текущего состояния в <<maps_chapter_08_before>>, где события являются необязательным побочным эффектом ...

[[maps_chapter_08_before]]
.Раньше: шина сообщений является необязательным дополнением
image::images/apwp_0901.png[]

((("message bus", "now the main entrypoint to service layer")))
((("service layer", "message bus as main entrypoint")))
...к ситуации в <<map_chapter_08_after>>, где всё идет по шине сообщений, а наше приложение было принципиально преобразовано в процессор сообщений.

[[map_chapter_08_after]]
.Шина сообщений теперь является основной точкой входа на уровень сервиса.
image::images/apwp_0902.png[]


[TIP]
====
Код для этой главы находится в ветке chapter_09_all_messagebus. https://oreil.ly/oKNkn[на GitHub]:

----
git clone https://github.com/cosmicpython/code.git
cd code
git checkout chapter_09_all_messagebus
# или, чтобы кодировать вместе, проверьте предыдущую главу:
git checkout chapter_08_events_and_message_bus
----
====

[role="pagebreak-before less_space"]
=== Новое требование приводит нас к новой архитектуре

((("situated software")))
((("events and the message bus", "transforming our app into message processor", "new requirement and new architecture")))
Рич Хикки говорит о _situated software_, то есть о программном обеспечении, которое работает в течение длительных периодов времени, управляя реальным процессом. Примеры включают системы управления складом, логистические планировщики и системы расчета заработной платы.

Такое программное обеспечение сложно написать, потому что в реальном мире физических объектов и ненадежных людей постоянно происходят неожиданные вещи. Например:

* Во время инвентаризации мы обнаруживаем, что три позиции:[<код>ПРУЖИННЫЙ МАТРАС</код>]были повреждены водой из-за протекающей крыши.
* У груза позиций:[<code>RELIABLE-FORK</code>]s отсутствует необходимая документация и он застрял на таможне, где находится уже в течение нескольких недель. Три позиции:[<code>RELIABLE-FORK</code>]s впоследствии не проходят проверку безопасности и уничтожаются.
* Глобальная нехватка блесток означает, что мы не сможем изготовить следующую партию позиции.:[<code>SPARKLY-BOOKCASE</code>].

((("batches", "batch quantities changed means deallocate and reallocate")))
В таких ситуациях мы узнаем о необходимости изменения количества партий, когда они уже находятся в системе. Может быть, кто-то ошибся номером в декларации, а может быть, какие-то диваны упали с грузовика. После разговора с представителями компанииfootnote:[ Моделирование на основе событий настолько популярно, что для облегчения сбора требований на основе событий и разработки модели предметной области была разработана практика под названием _event storming_.]
((("event storming")))
мы моделируем ситуацию, как на <<batch_changed_events_flow_diagram>>.


[[batch_changed_events_flow_diagram]]
.Изменение количества партии означает освобождение и перераспределение (deallocate and reallocate)
image::images/apwp_0903.png[]
[role="image-source"]
----
[ditaa, apwp_0903]
+----------+    /----\      +------------+       +--------------------+
| Batch    |--> |RULE| -->  | Deallocate | ----> | AllocationRequired |
| Quantity |    \----/      +------------+-+     +--------------------+-+
| Changed  |                  | Deallocate | ----> | AllocationRequired |
+----------+                  +------------+-+     +--------------------+-+
                                | Deallocate | ----> | AllocationRequired |
                                +------------+       +--------------------+
----

Событие, которое мы назовем `BatchQuantityChanged`, должно привести нас к изменению количества в партии, да, но также и к применению _бизнес правила_: если новое количество опускается до меньшего, чем уже распределённое общее количество, нам нужно _dealocate_ освободить места в этих заказы из этой партии. Затем каждый из них потребует нового распределения, которое мы можем зафиксировать как событие под названием `AllocationRequired` Требуемое распределение.

Возможно, вы уже ожидаете, что наша внутренняя шина сообщений и события помогут реализовать это требование. Мы могли бы определить службу под названием `change_batch_quantity`, которая знает, как корректировать количество партий, а также как _deallocate_ (освобождать) любые избыточные строки заказа, а затем каждое освобождение может генерировать событие `AllocationRequired`, которое может быть перенаправлено существующей службе `allocate` (распределения) в отдельные транзакции. И снова наша шина сообщений помогает нам обеспечивать соблюдение принципа единой ответственности и позволяет нам делать выбор в отношении транзакций и целостности данных.

==== Представим себе изменение архитектуры: всё будет [.keep-together]#event handler# Обработчик событий

((("event handlers", "imagined architecture in which everything is an event handler")))
((("events and the message bus", "transforming our app into message processor", "imagined architecture, everything will be an event handler")))
Но прежде чем запрыгнуть в это, подумай, куда мы направляемся.  Существует два вида потоков через нашу систему:

* Вызовы API, которые обрабатываются функцией уровня сервиса

* Внутренние события (которые могут быть вызваны как побочный эффект функции уровня сервиса) и их обработчики (которые, в свою очередь, вызывают функции уровня сервиса)

((("service functions", "making them event handlers")))
Разве не было бы проще, если бы все было обработчиком событий?  Если мы переосмыслим наши вызовы API как захват событий, функции уровня сервиса также могут быть обработчиками событий, и нам больше не нужно проводить различие между внутренними и внешними обработчиками событий:

* `services.allocate()` может быть обработчиком события `AllocationRequired` и может выдавать события `Allocated` в качестве его выходных данных.

* `services.add_batch()` может быть обработчиком события `BatchCreated`.footnote:[Если вы немного читали об архитектуре, управляемой событиями, вы можете подумать: "Некоторые из этих событий больше похожи на команды!" Терпение граждане! Мы пытаемся ввести одну концепцию за раз.   В <<chapter_10_commands,следующая глава>>, мы введем различие между командами и событиями.]
  ((("BatchCreated event", "services.add_batch as handler for")))

Наше новое требование будет соответствовать той же схеме:

* Событие под названием `BatchQuantityChanged` может вызывать обработчик под названием `change_batch_quantity()`.
  ((("BatchQuantityChanged event", "invoking handler change_batch_quantity")))

* И новые события `AllocationRequired`, которые он может вызвать, также могут быть переданы в `services.allocate() `, поэтому нет концептуальной разницы между совершенно новым распределением, исходящим от API, и перераспределением, которое запускается изнутри deallocate.
  ((("AllocationRequired event", "passing to services.allocate")))


((("preparatory refactoring workflow")))
Все это звучит как-то чересчур? Давайте работать над всем этим постепенно.  Мы будем следовать за рабочим процессом https://oreil.ly/W3RZM[Подготовительный рефакторинг], он же гласит "Сделайте изменение легким; затем сделайте легкое изменение":


1. Мы рефакторингуем наш уровень обслуживания в обработчики событий. Мы можем привыкнуть к идее о том, что события-это способ описания входов в систему. В частности, существующая функция `services.allocate()` станет обработчиком события под названием `AllocationRequired`.

2. Мы создаем сквозной тест,который помещает события `BatchQuantityChanged` в систему и принимает выходящие события `Allocated`.

3. Наша реализация концептуально будет очень простой: новый обработчик событий `BatchQuantityChanged`, реализация которого будет выдавать события `AllocationRequired`, которые, в свою очередь, будут обрабатываться точно таким же обработчиком распределений, который использует API.


По пути мы сделаем небольшую настройку шины сообщений и UoW, перенеся ответственность за размещение (put) новых событий на шине сообщений в саму шину сообщений.


=== Рефакторинг сервисных функций для обработчиков сообщений

((("events and the message bus", "transforming our app into message processor", "refactoring service functions to message handlers")))
((("service functions", "refactoring to message handlers")))
((("AllocationRequired event")))
((("BatchCreated event")))
Мы начинаем с определения двух событий, которые фиксируют наши текущие входные данные API - ++ AllocationRequired ++ и `BatchCreated`:

[[two_new_events]]
.BatchCreated and AllocationRequired events (src/allocation/domain/events.py)
====
[source,python]
----
@dataclass
class BatchCreated(Event):
    ref: str
    sku: str
    qty: int
    eta: Optional[date] = None

...

@dataclass
class AllocationRequired(Event):
    orderid: str
    sku: str
    qty: int
----
====

Then we rename _services.py_ to _handlers.py_; we add the existing message handler
for `send_out_of_stock_notification`; and most importantly, we change all the
handlers so that they have the same inputs, an event and a UoW:


[[services_to_handlers]]
.Handlers and services are the same thing (src/allocation/service_layer/handlers.py)
====
[source,python]
----
def add_batch(
        event: events.BatchCreated, uow: unit_of_work.AbstractUnitOfWork
):
    with uow:
        product = uow.products.get(sku=event.sku)
        ...


def allocate(
        event: events.AllocationRequired, uow: unit_of_work.AbstractUnitOfWork
) -> str:
    line = OrderLine(event.orderid, event.sku, event.qty)
    ...


def send_out_of_stock_notification(
        event: events.OutOfStock, uow: unit_of_work.AbstractUnitOfWork,
):
    email.send(
        'stock@made.com',
        f'Out of stock for {event.sku}',
    )
----
====


The change might be clearer as a diff:

[[services_to_handlers_diff]]
.Changing from services to handlers (src/allocation/service_layer/handlers.py)
====
[source,diff]
----
 def add_batch(
-        ref: str, sku: str, qty: int, eta: Optional[date],
-        uow: unit_of_work.AbstractUnitOfWork
+        event: events.BatchCreated, uow: unit_of_work.AbstractUnitOfWork
 ):
     with uow:
-        product = uow.products.get(sku=sku)
+        product = uow.products.get(sku=event.sku)
     ...


 def allocate(
-        orderid: str, sku: str, qty: int,
-        uow: unit_of_work.AbstractUnitOfWork
+        event: events.AllocationRequired, uow: unit_of_work.AbstractUnitOfWork
 ) -> str:
-    line = OrderLine(orderid, sku, qty)
+    line = OrderLine(event.orderid, event.sku, event.qty)
     ...

+
+def send_out_of_stock_notification(
+        event: events.OutOfStock, uow: unit_of_work.AbstractUnitOfWork,
+):
+    email.send(
     ...
----
====

Along the way, we've made our service-layer's API more structured and more consistent. It was a scattering of
primitives, and now it uses well-defined objects (see the following sidebar).

[role="nobreakinside less_space"]
.From Domain Objects, via Primitive Obsession, to [.keep-together]#Events as an Interface#
*******************************************************************************

((("service layer", "from domain objects to primitives to events as interface")))
((("primitives", "primitive obsession")))
((("primitives", "moving from domain objects to, in service layer")))
Some of you may remember <<primitive_obsession>>, in which we changed our service-layer API
from being in terms of domain objects to primitives. And now we're moving
back, but to different objects?  What gives?

In OO circles, people talk about _primitive obsession_ as an antipattern: avoid
primitives in public APIs, and instead wrap them with custom value classes, they
would say. In the Python world, a lot of people would be quite skeptical of
that as a rule of thumb. When mindlessly applied, it's certainly a recipe for
unnecessary complexity. So that's not what we're doing per se.

The move from domain objects to primitives bought us a nice bit of decoupling:
our client code was no longer coupled directly to the domain, so the service
layer could present an API that stays the same even if we decide to make changes
to our model, and vice versa.

So have we gone backward? Well, our core domain model objects are still free to
vary, but instead we've coupled the external world to our event classes.
They're part of the domain too, but the hope is that they vary less often, so
they're a sensible artifact to couple on.

And what have we bought ourselves? Now, when invoking a use case in our application,
we no longer need to remember a particular combination of primitives, but just a single
event class that represents the input to our application. That's conceptually
quite nice. On top of that, as you'll see in <<appendix_validation>>, those
event classes can be a nice place to do some input validation.
*******************************************************************************


==== The Message Bus Now Collects Events from the UoW

((("message bus", "now collecting events from UoW")))
((("Unit of Work pattern", "message bus now collecting events from UoW")))
((("dependencies", "UoW no longer dependent on message bus")))
Our event handlers now need a UoW. In addition, as our message bus becomes
more central to our application, it makes sense to put it explicitly in charge of
collecting and processing new events. There was a bit of a circular dependency
between the UoW and message bus until now, so this will make it one-way.  Instead
of having the UoW _push_ events onto the message bus, we will have the message
bus _pull_ events from the UoW.


[[handle_has_uow_and_queue]]
.Handle takes a UoW and manages a queue (src/allocation/service_layer/messagebus.py)
====
[source,python]
[role="non-head"]
----
def handle(event: events.Event, uow: unit_of_work.AbstractUnitOfWork):  #<1>
    queue = [event]  #<2>
    while queue:
        event = queue.pop(0)  #<3>
        for handler in HANDLERS[type(event)]:  #<3>
            handler(event, uow=uow)  #<4>
            queue.extend(uow.collect_new_events())  #<5>
----
====

<1> The message bus now gets passed the UoW each time it starts up.
<2> When we begin handling our first event, we start a queue.
<3> We pop events from the front of the queue and invoke their handlers (the
    [.keep-together]#`HANDLERS`# dict hasn't changed; it still maps event types to handler functions).
<4> The message bus passes the UoW down to each handler.
<5> After each handler finishes, we collect any new events that have been
    generated and add them to the queue.

In _unit_of_work.py_, `publish_events()` becomes a less active method,
`collect_new_events()`:


[[uow_collect_new_events]]
.UoW no longer puts events directly on the bus (src/allocation/service_layer/unit_of_work.py)
====
[source,diff]
----
-from . import messagebus  #<1>
-


 class AbstractUnitOfWork(abc.ABC):
@@ -23,13 +21,11 @@ class AbstractUnitOfWork(abc.ABC):

     def commit(self):
         self._commit()
-        self.publish_events()  #<2>

-    def publish_events(self):
+    def collect_new_events(self):
         for product in self.products.seen:
             while product.events:
-                event = product.events.pop(0)
-                messagebus.handle(event)
+                yield product.events.pop(0)  #<3>

----
====

<1> The `unit_of_work` module now no longer depends on `messagebus`.
<2> We no longer `publish_events` automatically on commit. The message bus
    is keeping track of the event queue instead.
<3> And the UoW no longer actively puts events on the message bus; it
    just makes them available.

//IDEA: we can definitely get rid of _commit() now right?
// (EJ2) at this point _commit() doesn't serve any purpose, so it could be deleted.
//       unsure if deleting it would be confusing at this point.

[role="pagebreak-before less_space"]
==== Our Tests Are All Written in Terms of Events Too

((("events and the message bus", "transforming our app into message processor", "tests writtern to in terms of events")))
((("testing", "tests written in terms of events")))
Our tests now operate by creating events and putting them on the
message bus, rather than invoking service-layer functions directly:


[[handler_tests]]
.Handler tests use events (tests/unit/test_handlers.py)
====
[source,diff]
----
class TestAddBatch:

     def test_for_new_product(self):
         uow = FakeUnitOfWork()
-        services.add_batch("b1", "CRUNCHY-ARMCHAIR", 100, None, uow)
+        messagebus.handle(
+            events.BatchCreated("b1", "CRUNCHY-ARMCHAIR", 100, None), uow
+        )
         assert uow.products.get("CRUNCHY-ARMCHAIR") is not None
         assert uow.committed

...

 class TestAllocate:

     def test_returns_allocation(self):
         uow = FakeUnitOfWork()
-        services.add_batch("batch1", "COMPLICATED-LAMP", 100, None, uow)
-        result = services.allocate("o1", "COMPLICATED-LAMP", 10, uow)
+        messagebus.handle(
+            events.BatchCreated("batch1", "COMPLICATED-LAMP", 100, None), uow
+        )
+        result = messagebus.handle(
+            events.AllocationRequired("o1", "COMPLICATED-LAMP", 10), uow
+        )
         assert result == "batch1"
----
====


[[temporary_ugly_hack]]
==== A Temporary Ugly Hack: The Message Bus Has to Return Results

((("events and the message bus", "transforming our app into message processor", "temporary hack, message bus returning results")))
((("message bus", "returning results in temporary hack")))
Our API and our service layer currently want to know the allocated batch reference
when they invoke our `allocate()` handler. This means we need to put in
a temporary hack on our message bus to let it return events:

[[hack_messagebus_results]]
.Message bus returns results (src/allocation/service_layer/messagebus.py)
====
[source,diff]
----
 def handle(event: events.Event, uow: unit_of_work.AbstractUnitOfWork):
+    results = []
     queue = [event]
     while queue:
         event = queue.pop(0)
         for handler in HANDLERS[type(event)]:
-            handler(event, uow=uow)
+            results.append(handler(event, uow=uow))
             queue.extend(uow.collect_new_events())
+    return results
----
====

// IDEA (hynek) inline the r=, the addition of a meaningless variable is distracting.


((("events and the message bus", "transforming our app into message processor", "modifying API to work with events")))
((("APIs", "modifying API to work with events")))
It's because we're mixing the read and write responsibilities in our system.
We'll come back to fix this wart in <<chapter_12_cqrs>>.


==== Modifying Our API to Work with Events

[[flask_uses_messagebus]]
.Flask changing to message bus as a diff (src/allocation/entrypoints/flask_app.py)
====
[source,diff]
----
 @app.route("/allocate", methods=['POST'])
 def allocate_endpoint():
     try:
-        batchref = services.allocate(
-            request.json['orderid'],  #<1>
-            request.json['sku'],
-            request.json['qty'],
-            unit_of_work.SqlAlchemyUnitOfWork(),
+        event = events.AllocationRequired(  #<2>
+            request.json['orderid'], request.json['sku'], request.json['qty'],
         )
+        results = messagebus.handle(event, unit_of_work.SqlAlchemyUnitOfWork())  #<3>
+        batchref = results.pop(0)
     except InvalidSku as e:
----
====

<1> Instead of calling the service layer with a bunch of primitives extracted
    from the request JSON...

<2> We instantiate an event.

<3> Then we pass it to the message bus.

And we should be back to a fully functional application, but one that's now
fully event-driven:

* What used to be service-layer functions are now event handlers.

* That makes them the same as the functions we invoke for handling internal events raised by
  our domain model.

* We use events as our data structure for capturing inputs to the system,
  as well as for handing off of internal work packages.

* The entire app is now best described as a message processor, or an event processor
  if you prefer.  We'll talk about the distinction in the
  <<chapter_10_commands, next chapter>>.



=== Implementing Our New Requirement

((("reallocation", "sequence diagram for flow")))
((("events and the message bus", "transforming our app into message processor", "implementing the new requirement", id="ix_evntMBMPreq")))
We're done with our refactoring phase. Let's see if we really have "made the
change easy."  Let's implement our new requirement, shown in <<reallocation_sequence_diagram>>: we'll receive as our
inputs some new `BatchQuantityChanged` events and pass them to a handler, which in
turn might emit some `AllocationRequired` events, and those in turn will go
back to our existing handler for reallocation.

[role="width-75"]
[[reallocation_sequence_diagram]]
.Sequence diagram for reallocation flow
image::images/apwp_0904.png[]
[role="image-source"]
----
[plantuml, apwp_0904, config=plantuml.cfg]
@startuml
scale 4

API -> MessageBus : BatchQuantityChanged event

group BatchQuantityChanged Handler + Unit of Work 1
    MessageBus -> Domain_Model : change batch quantity
    Domain_Model -> MessageBus : emit AllocationRequired event(s)
end


group AllocationRequired Handler + Unit of Work 2 (or more)
    MessageBus -> Domain_Model : allocate
end

@enduml
----

WARNING: When you split things out like this across two units of work,
    you now have two database transactions, so you are opening yourself up
    to integrity issues: something could happen that means the first transaction completes
    but the second one does not. You'll need to think about whether this is acceptable,
    and whether you need to notice when it happens and do something about it.
    See <<footguns>> for more discussion.
    ((("data integrity", "issues arising from splitting operation across two UoWs")))
    ((("Unit of Work pattern", "splitting operations across two UoWs")))



==== Our New Event

((("BatchQuantityChanged event", "implementing")))
The event that tells us a batch quantity has changed is simple; it just
needs a batch reference and a new quantity:


[[batch_quantity_changed_event]]
.New event (src/allocation/domain/events.py)
====
[source,python]
----
@dataclass
class BatchQuantityChanged(Event):
    ref: str
    qty: int
----
====

[[test-driving-ch9]]
=== Test-Driving a New Handler

((("testing", "tests written in terms of events", "handler tests for change_batch_quantity")))
((("events and the message bus", "transforming our app into message processor", "test driving new handler")))
((("events and the message bus", "transforming our app into message processor", "implementing the new requirement", startref="ix_evntMBMPreq")))
((("change_batch_quantity", "handler tests for")))
Following the lessons learned in <<chapter_04_service_layer>>,
we can operate in "high gear" and write our unit tests at the highest
possible level of abstraction, in terms of events. Here's what they might
look like:


[[test_change_batch_quantity_handler]]
.Handler tests for change_batch_quantity (tests/unit/test_handlers.py)
====
[source,python]
----
class TestChangeBatchQuantity:

    def test_changes_available_quantity(self):
        uow = FakeUnitOfWork()
        messagebus.handle(
            events.BatchCreated("batch1", "ADORABLE-SETTEE", 100, None), uow
        )
        [batch] = uow.products.get(sku="ADORABLE-SETTEE").batches
        assert batch.available_quantity == 100  #<1>

        messagebus.handle(events.BatchQuantityChanged("batch1", 50), uow)

        assert batch.available_quantity == 50  #<1>


    def test_reallocates_if_necessary(self):
        uow = FakeUnitOfWork()
        event_history = [
            events.BatchCreated("batch1", "INDIFFERENT-TABLE", 50, None),
            events.BatchCreated("batch2", "INDIFFERENT-TABLE", 50, date.today()),
            events.AllocationRequired("order1", "INDIFFERENT-TABLE", 20),
            events.AllocationRequired("order2", "INDIFFERENT-TABLE", 20),
        ]
        for e in event_history:
            messagebus.handle(e, uow)
        [batch1, batch2] = uow.products.get(sku="INDIFFERENT-TABLE").batches
        assert batch1.available_quantity == 10
        assert batch2.available_quantity == 50

        messagebus.handle(events.BatchQuantityChanged("batch1", 25), uow)

        # order1 or order2 will be deallocated, so we'll have 25 - 20
        assert batch1.available_quantity == 5  #<2>
        # and 20 will be reallocated to the next batch
        assert batch2.available_quantity == 30  #<2>
----
====

<1> The simple case would be trivially easy to implement; we just
    modify a quantity.

<2> But if we try to change the quantity to less than
    has been allocated, we'll need to deallocate at least one order,
    and we expect to reallocate it to a new batch.



==== Implementation

((("change_batch_quantity", "implementation, handler delegating to model layer")))
Our new handler is very simple:

[[change_quantity_handler]]
.Handler delegates to model layer (src/allocation/service_layer/handlers.py)
====
[source,python]
----
def change_batch_quantity(
        event: events.BatchQuantityChanged, uow: unit_of_work.AbstractUnitOfWork
):
    with uow:
        product = uow.products.get_by_batchref(batchref=event.ref)
        product.change_batch_quantity(ref=event.ref, qty=event.qty)
        uow.commit()
----
====

// TODO (DS): Indentation looks off


((("repositories", "new query type on our repository")))
We realize we'll need a new query type on our repository:

[[get_by_batchref]]
.A new query type on our repository (src/allocation/adapters/repository.py)
====
[source,python,highlight="7,22,32"]
----
class AbstractRepository(abc.ABC):
    ...

    def get(self, sku) -> model.Product:
        ...

    def get_by_batchref(self, batchref) -> model.Product:
        product = self._get_by_batchref(batchref)
        if product:
            self.seen.add(product)
        return product

    @abc.abstractmethod
    def _add(self, product: model.Product):
        raise NotImplementedError

    @abc.abstractmethod
    def _get(self, sku) -> model.Product:
        raise NotImplementedError

    @abc.abstractmethod
    def _get_by_batchref(self, batchref) -> model.Product:
        raise NotImplementedError
    ...

class SqlAlchemyRepository(AbstractRepository):
    ...

    def _get(self, sku):
        return self.session.query(model.Product).filter_by(sku=sku).first()

    def _get_by_batchref(self, batchref):
        return self.session.query(model.Product).join(model.Batch).filter(
            orm.batches.c.reference == batchref,
        ).first()

----
====

((("faking", "FakeRepository", "new query type on")))
And on our `FakeRepository` too:

[[fakerepo_get_by_batchref]]
.Updating the fake repo too (tests/unit/test_handlers.py)
====
[source,python]
[role="non-head"]
----
class FakeRepository(repository.AbstractRepository):
    ...

    def _get(self, sku):
        return next((p for p in self._products if p.sku == sku), None)

    def _get_by_batchref(self, batchref):
        return next((
            p for p in self._products for b in p.batches
            if b.reference == batchref
        ), None)
----
====


NOTE: We're adding a query to our repository to make this use case easier to
    implement. So long as our query is returning a single aggregate, we're not
    bending any rules. If you find yourself writing complex queries on your
    repositories, you might want to consider a different design. Methods like
    `get_most_popular_products` or `find_products_by_order_id` in particular
    would definitely trigger our spidey sense. <<chapter_11_external_events>>
    and the <<epilogue_1_how_to_get_there_from_here, epilogue>> have some tips
    on managing complex queries.
    ((("aggregates", "query on repository returning single aggregate")))

==== A New Method on the Domain Model

((("domain model", "new method on, change_batch_quantity")))
We add the new method to the model, which does the quantity change and
deallocation(s) inline and publishes a new event.  We also modify the existing
allocate function to publish an event:


[[change_batch_model_layer]]
.Our model evolves to capture the new requirement (src/allocation/domain/model.py)
====
[source,python]
----
class Product:
    ...

    def change_batch_quantity(self, ref: str, qty: int):
        batch = next(b for b in self.batches if b.reference == ref)
        batch._purchased_quantity = qty
        while batch.available_quantity < 0:
            line = batch.deallocate_one()
            self.events.append(
                events.AllocationRequired(line.orderid, line.sku, line.qty)
            )
...

class Batch:
    ...

    def deallocate_one(self) -> OrderLine:
        return self._allocations.pop()
----
====

((("message bus", "wiring up new event handlers to")))
We wire up our new handler:


[[full_messagebus]]
.The message bus grows (src/allocation/service_layer/messagebus.py)
====
[source,python]
----
HANDLERS = {
    events.BatchCreated: [handlers.add_batch],
    events.BatchQuantityChanged: [handlers.change_batch_quantity],
    events.AllocationRequired: [handlers.allocate],
    events.OutOfStock: [handlers.send_out_of_stock_notification],

}  # type: Dict[Type[events.Event], List[Callable]]
----
====

And our new requirement is fully implemented.

[[fake_message_bus]]
=== Optionally: Unit Testing Event Handlers in Isolation with a Fake Message Bus

((("message bus", "unit testing event handlers with fake message bus")))
((("testing", "tests written in terms of events", "unit testing event handlers with fake message bus")))
((("events and the message bus", "transforming our app into message processor", "unit testing event handlers with fake message bus")))
Our main test for the reallocation workflow is _edge-to-edge_
(see the example code in <<test-driving-ch9>>). It uses
the real message bus, and it tests the whole flow, where the `BatchQuantityChanged`
event handler triggers deallocation, and emits new `AllocationRequired` events, which in
turn are handled by their own handlers. One test covers a chain of multiple
events and handlers.

Depending on the complexity of your chain of events, you may decide that you
want to test some handlers in isolation from one another. You can do this
using a "fake" message bus.

((("Unit of Work pattern", "fake message bus implemented in UoW")))
In our case, we actually intervene by modifying the `publish_events()` method
on `FakeUnitOfWork` and decoupling it from the real message bus, instead making
it record what events it sees:


[[fake_messagebus]]
.Fake message bus implemented in UoW (tests/unit/test_handlers.py)
====
[source,python]
[role="non-head"]
----
class FakeUnitOfWorkWithFakeMessageBus(FakeUnitOfWork):

    def __init__(self):
        super().__init__()
        self.events_published = []  # type: List[events.Event]

    def publish_events(self):
        for product in self.products.seen:
            while product.events:
                self.events_published.append(product.events.pop(0))
----
====

((("reallocation", "testing in isolation using fake message bus")))
Now when we invoke `messagebus.handle()` using the `FakeUnitOfWorkWithFakeMessageBus`,
it runs only the handler for that event. So we can write a more isolated unit
test: instead of checking all the side effects, we just check that
`BatchQuantityChanged` leads to `AllocationRequired` if the quantity drops
below the total already allocated:

[role="nobreakinside less_space"]
[[test_handler_in_isolation]]
.Testing reallocation in isolation (tests/unit/test_handlers.py)
====
[source,python]
[role="non-head"]
----
def test_reallocates_if_necessary_isolated():
    uow = FakeUnitOfWorkWithFakeMessageBus()

    # test setup as before
    event_history = [
        events.BatchCreated("batch1", "INDIFFERENT-TABLE", 50, None),
        events.BatchCreated("batch2", "INDIFFERENT-TABLE", 50, date.today()),
        events.AllocationRequired("order1", "INDIFFERENT-TABLE", 20),
        events.AllocationRequired("order2", "INDIFFERENT-TABLE", 20),
    ]
    for e in event_history:
        messagebus.handle(e, uow)
    [batch1, batch2] = uow.products.get(sku="INDIFFERENT-TABLE").batches
    assert batch1.available_quantity == 10
    assert batch2.available_quantity == 50

    messagebus.handle(events.BatchQuantityChanged("batch1", 25), uow)

    # assert on new events emitted rather than downstream side-effects
    [reallocation_event] = uow.events_published
    assert isinstance(reallocation_event, events.AllocationRequired)
    assert reallocation_event.orderid in {'order1', 'order2'}
    assert reallocation_event.sku == 'INDIFFERENT-TABLE'
----
====

Whether you want to do this or not depends on the complexity of your chain of
events. We say, start out with edge-to-edge testing, and resort to
this only if necessary.

[role="nobreakinside less_space"]
.Exercise for the Reader
*******************************************************************************

((("message bus", "abstract message bus and its real and fake versions")))
A great way to force yourself to really understand some code is to refactor it.
In the discussion of testing handlers in isolation, we used something called
`FakeUnitOfWorkWithFakeMessageBus`, which is unnecessarily complicated and
violates the SRP.

((("Singleton pattern, messagebus.py implementing")))
If we change the message bus to being a class,footnote:[The "simple"
implementation in this chapter essentially uses the _messagebus.py_ module
itself to implement the Singleton Pattern.]
then building a `FakeMessageBus` is more straightforward:

[[abc_for_fake_messagebus]]
.An abstract message bus and its real and fake versions
====
[source,python]
[role="skip"]
----
class AbstractMessageBus:
    HANDLERS: Dict[Type[events.Event], List[Callable]]

    def handle(self, event: events.Event):
        for handler in self.HANDLERS[type(event)]:
            handler(event)


class MessageBus(AbstractMessageBus):
    HANDLERS = {
        events.OutOfStock: [send_out_of_stock_notification],

    }


class FakeMessageBus(messagebus.AbstractMessageBus):
    def __init__(self):
        self.events_published = []  # type: List[events.Event]
        self.HANDLERS = {
            events.OutOfStock: [lambda e: self.events_published.append(e)]
        }
----
====

So jump into the code on
https://github.com/cosmicpython/code/tree/chapter_09_all_messagebus[GitHub] and see if you can get a class-based version
working, and then write a version of `test_reallocates_if_necessary_isolated()`
from earlier.

We use a class-based message bus in <<chapter_13_dependency_injection>>,
if you need more inspiration.
*******************************************************************************

=== Wrap-Up

Let's look back at what we've achieved, and think about why we did it.

==== What Have We Achieved?

Events are simple dataclasses that define the data structures for inputs
  and internal messages within our system. This is quite powerful from a DDD
  standpoint, since events often translate really well into business language
  (look up __event storming__ if you haven't already).

Handlers are the way we react to events. They can call down to our
  model or call out to external services.  We can define multiple
  handlers for a single event if we want to. Handlers can also raise other
  events. This allows us to be very granular about what a handler does
  and really stick to the SRP.


==== Why Have We Achieved?

((("events and the message bus", "transforming our app into message processor", "whole app as message bus, trade-offs")))
((("message bus", "whole app as, trade-offs")))
Our ongoing objective with these architectural patterns is to try to have
the complexity of our application grow more slowly than its size.  When we
go all in on the message bus, as always we pay a price in terms of architectural
complexity (see <<chapter_09_all_messagebus_tradeoffs>>), but we buy ourselves a
pattern that can handle almost arbitrarily complex requirements without needing
any further conceptual or architectural change to the way we do things.

Here we've added quite a complicated use case (change quantity, deallocate,
start new transaction, reallocate, publish external notification), but
architecturally, there's been no cost in terms of complexity. We've added new
events, new handlers, and a new external adapter (for email), all of which are
existing categories of _things_ in our architecture that we understand and know
how to reason about, and that are easy to explain to newcomers.  Our moving
parts each have one job, they're connected to each other in well-defined ways,
and there are no unexpected side effects.

[[chapter_09_all_messagebus_tradeoffs]]
[options="header"]
.Whole app is a message bus: the trade-offs
|===
|Pros|Cons
a|
* Handlers and services are the same thing, so that's simpler.
* We have a nice data structure for inputs to the system.

a|
* A message bus is still a slightly unpredictable way of doing things from
  a web point of view. You don't know in advance when things are going to end.
* There will be duplication of fields and structure between model objects and events, which will have a maintenance cost. Adding a field to one usually means adding a field to at least
  one of the others.
|===

((("events and the message bus", "transforming our app into message processor", startref="ix_evntMBMP")))
Now, you may be wondering, where are those `BatchQuantityChanged` events
going to come from? The answer is revealed in a couple chapters' time.  But
first, let's talk about <<chapter_10_commands,events versus commands>>.

